{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNL3n0k3jvyQRTyo6hDfWQs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chloebh9/Recommendation-system/blob/main/L03_1_Rating_Prediction_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ati9GZGRlE6s",
        "outputId": "cdbbacd2-9b64-4b53-9f9d-90aa8bbd67e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-10 06:02:28--  https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 261978986 (250M) [application/zip]\n",
            "Saving to: ‘ml-25m.zip’\n",
            "\n",
            "ml-25m.zip          100%[===================>] 249.84M  35.9MB/s    in 6.5s    \n",
            "\n",
            "2024-04-10 06:02:35 (38.4 MB/s) - ‘ml-25m.zip’ saved [261978986/261978986]\n",
            "\n",
            "Archive:  ml-25m.zip\n",
            "   creating: ml-25m/\n",
            "  inflating: ml-25m/tags.csv         \n",
            "  inflating: ml-25m/links.csv        \n",
            "  inflating: ml-25m/README.txt       \n",
            "  inflating: ml-25m/ratings.csv      \n",
            "  inflating: ml-25m/genome-tags.csv  \n",
            "  inflating: ml-25m/genome-scores.csv  \n",
            "  inflating: ml-25m/movies.csv       \n"
          ]
        }
      ],
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
        "!unzip ml-25m.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "with open(\"ml-25m/ratings.csv\", \"r\") as f:\n",
        "    print(f.readline()) # skip column names\n",
        "\n",
        "    users = []\n",
        "    items = []\n",
        "    ratings = []\n",
        "\n",
        "    for line in f:\n",
        "        uid, mid, rating, timestamp = line.split(\",\")\n",
        "        users.append(int(uid))\n",
        "        items.append(int(mid))\n",
        "        ratings.append(float(rating))\n",
        "\n",
        "    users = np.array(users)\n",
        "    items = np.array(items)\n",
        "    ratings = np.array(ratings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61aka_1pmZDO",
        "outputId": "b4b6429d-d72b-4ce8-de1b-5de6cc01cb00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "userId,movieId,rating,timestamp\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse = ((ratings - ratings.mean()) ** 2).mean() ** 0.5\n",
        "print(rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcRSVn8iob0W",
        "outputId": "6280db4b-b5bd-41d8-da92-3ab72a94913d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0607439399275531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = ratings.mean()\n",
        "user_bias = np.zeros(users.max() + 1)\n",
        "item_bias = np.zeros(items.max() + 1)"
      ],
      "metadata": {
        "id": "FMsM7zJep0eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1\n",
        "lmd = 0.001\n",
        "\n",
        "n_ratings = len(ratings)\n",
        "n_users = len(user_bias)\n",
        "n_items = len(item_bias)\n",
        "\n",
        "for epoch in range(20):\n",
        "\n",
        "    h = alpha + user_bias[users] + item_bias[items]\n",
        "    diff = h - ratings\n",
        "\n",
        "    rmse = (diff ** 2).mean() ** 0.5\n",
        "    print(f\"epoch: {epoch}, rmse: {rmse}\")\n",
        "\n",
        "    grd_alpha = diff.mean()\n",
        "    grd_user_bias = np.bincount(users, weights=diff)/n_ratings + lmd * user_bias/n_users\n",
        "    grd_item_bias = np.bincount(items, weights=diff)/n_ratings + lmd * item_bias/n_items\n",
        "\n",
        "    alpha = alpha - lr * grd_alpha\n",
        "    user_bias = user_bias - lr * grd_user_bias\n",
        "    item_bias = item_bias - lr * grd_item_bias\n",
        "\n",
        "h = alpha + user_bias[users] + item_bias[items]\n",
        "diff = h - ratings\n",
        "\n",
        "rmse = (diff ** 2).mean() ** 0.5\n",
        "print(f\"rmse: {rmse}, alpha: {alpha}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCpPdZvDqjYc",
        "outputId": "8083b7f3-6567-4854-fb35-c2c0b5fcebd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, rmse: 1.0607439399275531\n",
            "epoch: 1, rmse: 1.0606227041512328\n",
            "epoch: 2, rmse: 1.0605018083005335\n",
            "epoch: 3, rmse: 1.0603812424803158\n",
            "epoch: 4, rmse: 1.0602610053766328\n",
            "epoch: 5, rmse: 1.060141095681595\n",
            "epoch: 6, rmse: 1.0600215120933394\n",
            "epoch: 7, rmse: 1.0599022533159907\n",
            "epoch: 8, rmse: 1.0597833180596394\n",
            "epoch: 9, rmse: 1.0596647050403154\n",
            "epoch: 10, rmse: 1.0595464129799474\n",
            "epoch: 11, rmse: 1.0594284406063486\n",
            "epoch: 12, rmse: 1.059310786653174\n",
            "epoch: 13, rmse: 1.0591934498599036\n",
            "epoch: 14, rmse: 1.0590764289718062\n",
            "epoch: 15, rmse: 1.0589597227399157\n",
            "epoch: 16, rmse: 1.0588433299209998\n",
            "epoch: 17, rmse: 1.0587272492775308\n",
            "epoch: 18, rmse: 1.0586114795776682\n",
            "epoch: 19, rmse: 1.0584960195952156\n",
            "rmse: 1.0583808681095987, alpha: 3.5313318465676904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "ratings_tensor = torch.from_numpy(ratings)\n",
        "\n",
        "alpha = torch.tensor(ratings.mean())\n",
        "alpha.requires_grad_(True)\n",
        "user_bias = torch.zeros(users.max() + 1, requires_grad=True)\n",
        "item_bias = torch.zeros(items.max() + 1, requires_grad=True)\n",
        "\n",
        "optim = torch.optim.Adam([alpha, user_bias, item_bias], lr=0.3)\n",
        "\n",
        "lmd = 0.001\n",
        "\n",
        "for epoch in range(20):\n",
        "    h = alpha + user_bias[users] + item_bias[items]\n",
        "    mse = ((h - ratings_tensor) ** 2).mean()\n",
        "    reg = lmd * ((item_bias ** 2).mean() + (user_bias ** 2).mean())\n",
        "    cost = mse + reg\n",
        "\n",
        "    optim.zero_grad()\n",
        "    cost.backward()\n",
        "    optim.step()\n",
        "\n",
        "    # with torch.no_grad():\n",
        "    #     print((mse ** 0.5).item(), alpha.item())\n",
        "\n",
        "    with torch.no_grad():\n",
        "        rmse = ((h - ratings_tensor) ** 2).mean() ** 0.5\n",
        "        print(f\"epoch: {epoch}, rmse: {rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akBm9Rmz39zN",
        "outputId": "9fd30d0a-bd6a-4817-dc49-581e739f9bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, rmse: 1.0607439399275533\n",
            "epoch: 1, rmse: 0.9669325508290363\n",
            "epoch: 2, rmse: 0.9497903759085393\n",
            "epoch: 3, rmse: 0.9171939835020677\n",
            "epoch: 4, rmse: 0.8941977578397844\n",
            "epoch: 5, rmse: 0.9097900925389514\n",
            "epoch: 6, rmse: 0.9059687935173155\n",
            "epoch: 7, rmse: 0.8945284306008058\n",
            "epoch: 8, rmse: 0.8960262980198718\n",
            "epoch: 9, rmse: 0.892189653674854\n",
            "epoch: 10, rmse: 0.8781706889731724\n",
            "epoch: 11, rmse: 0.8717876177492263\n",
            "epoch: 12, rmse: 0.8759573490807723\n",
            "epoch: 13, rmse: 0.8761336781525304\n",
            "epoch: 14, rmse: 0.8709138637513829\n",
            "epoch: 15, rmse: 0.8687833630096475\n",
            "epoch: 16, rmse: 0.8684808875097653\n",
            "epoch: 17, rmse: 0.8644695056645418\n",
            "epoch: 18, rmse: 0.8603502917327274\n",
            "epoch: 19, rmse: 0.8612059545815784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "lmd = 0.001\n",
        "\n",
        "alpha = ratings.mean()\n",
        "user_bias = np.zeros(users.max() + 1)\n",
        "item_bias = np.zeros(items.max() + 1)\n",
        "\n",
        "for epoch in range(10):\n",
        "    h = alpha + user_bias[users] + item_bias[items]\n",
        "    rmse = ((h - ratings) ** 2).mean() ** 0.5\n",
        "    print(rmse)\n",
        "\n",
        "    alpha = (ratings - (user_bias[users] + item_bias[items])).mean()\n",
        "    user_bias = np.bincount(users, weights=ratings - (alpha + item_bias[items])) / (np.bincount(users) + lmd)\n",
        "    item_bias = np.bincount(items, weights=ratings - (alpha + user_bias[users])) / (np.bincount(items) + lmd)\n",
        "\n",
        "h = alpha + user_bias[users] + item_bias[items]\n",
        "rmse = ((h - ratings) ** 2).mean() ** 0.5\n",
        "print(f\"final rmse: {rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ENo3Rcy4F0J",
        "outputId": "253fac1f-1a7c-4d3f-c4d5-f205cf88125b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0607439399275531\n",
            "0.8663159834756426\n",
            "0.8510867185839471\n",
            "0.8503568292676987\n",
            "0.8503078899843288\n",
            "0.8503025377563744\n",
            "0.8503016450633218\n",
            "0.8503014646716495\n",
            "0.8503014258804191\n",
            "0.8503014173907169\n",
            "final rmse: 0.8503014155289849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h7NsPYpb83Ph"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}