{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMpu5GGfscGMwYkoUrOHgHs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chloebh9/Recommendation-system/blob/main/L11_1_Temporal_Recommender_Systems_Practiceipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEKZCm4qo7c7",
        "outputId": "2c27e472-8978-4bf1-eeb7-b217e0398ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-11 03:40:55--  https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 978202 (955K) [application/zip]\n",
            "Saving to: ‘ml-latest-small.zip’\n",
            "\n",
            "ml-latest-small.zip 100%[===================>] 955.28K  2.67MB/s    in 0.3s    \n",
            "\n",
            "2024-06-11 03:40:56 (2.67 MB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
            "\n",
            "Archive:  ml-latest-small.zip\n",
            "   creating: ml-latest-small/\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n"
          ]
        }
      ],
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "!unzip ml-latest-small.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "goz_ZCi0ukvp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wPUlkOKros1",
        "outputId": "9f223300-c97d-4a20-b406-3dd48187e1e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "users, items, ratings, times = [], [], [], []\n",
        "\n",
        "with open(\"ml-latest-small/ratings.csv\", \"r\") as f:\n",
        "    print(f.readline())\n",
        "\n",
        "    for line in f:\n",
        "        uid, iid, rating, timestamp = line.split(\",\")\n",
        "        users.append(int(uid))\n",
        "        items.append(int(iid))\n",
        "        ratings.append(float(rating))\n",
        "        times.append(int(timestamp))\n",
        "\n",
        "n_ratings = len(users)\n",
        "\n",
        "users = torch.LongTensor(users)\n",
        "items = torch.LongTensor(items)\n",
        "ratings = torch.FloatTensor(ratings)\n",
        "times = torch.LongTensor(times)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_laVtSZpHcn",
        "outputId": "b96bc23f-ab0c-46de-f5e4-ada0f333d544"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "userId,movieId,rating,timestamp\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " train, test 분리"
      ],
      "metadata": {
        "id": "6RzwIFTmsK1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(n_ratings * 0.8)\n",
        "shuffled = torch.randperm(n_ratings)\n",
        "\n",
        "users_train = users[shuffled[:train_size]].to(device)\n",
        "items_train = items[shuffled[:train_size]].to(device)\n",
        "ratings_train = ratings[shuffled[:train_size]].to(device)\n",
        "times_train = times[shuffled[:train_size]].to(device)\n",
        "\n",
        "users_test = users[shuffled[train_size:]].to(device)\n",
        "items_test = items[shuffled[train_size:]].to(device)\n",
        "ratings_test = ratings[shuffled[train_size:]].to(device)\n",
        "times_test = times[shuffled[train_size:]].to(device)"
      ],
      "metadata": {
        "id": "XSTBYLQYpOQU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(users_train.shape)\n",
        "print(items_train.shape)\n",
        "print(ratings_train)\n",
        "print(times_train)\n",
        "\n",
        "#shape는 다 80668"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_mZJqw8uBX-",
        "outputId": "8c8c4d73-1397-462c-dc50-55f2018c87c1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([80668])\n",
            "torch.Size([80668])\n",
            "tensor([3.0000, 0.5000, 4.0000,  ..., 4.0000, 4.5000, 5.0000], device='cuda:0')\n",
            "tensor([1258418710, 1518197698,  953610692,  ..., 1460136755, 1180447438,\n",
            "         967920117], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Bias 모델 파라미터 생성"
      ],
      "metadata": {
        "id": "hSrswHwDsNDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_users = max(users) + 1\n",
        "n_items = max(items) + 1\n",
        "\n",
        "mean = ratings_train.mean()\n",
        "b_u = torch.zeros(n_users, requires_grad=True, device=device)\n",
        "b_i = torch.zeros(n_items, requires_grad=True, device=device)\n",
        "\n",
        "lmd = 0.00003\n",
        "# optim = torch.optim.Adam([b_u, b_i], lr=0.1)\n",
        "optim = torch.optim.Adam([b_u, b_i], lr=0.1, weight_decay=0.00006)\n",
        "criteria = torch.nn.MSELoss()\n",
        "\n",
        "for epoch in range(1000):\n",
        "    h = mean + b_u[users_train] + b_i[items_train]\n",
        "    reg = lmd * ((b_u ** 2).sum() + (b_i ** 2).sum())\n",
        "    cost = criteria(h, ratings_train) + reg\n",
        "\n",
        "    optim.zero_grad()\n",
        "    cost.backward()\n",
        "    optim.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        h_train = mean + b_u[users_train] + b_i[items_train]\n",
        "        cost_train = criteria(h_train, ratings_train)\n",
        "\n",
        "        h_test = mean + b_u[users_test] + b_i[items_test]\n",
        "        cost_test = criteria(h_test, ratings_test)\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(epoch, cost_train.item(), cost_test.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6087ThSsGIP",
        "outputId": "4dcc0e45-aed1-47e9-d004-7075e2020c09"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.9509391188621521 0.9687032699584961\n",
            "100 0.6682974696159363 0.749301552772522\n",
            "200 0.6683434247970581 0.7492996454238892\n",
            "300 0.6683433651924133 0.7492996454238892\n",
            "400 0.668343186378479 0.749298632144928\n",
            "500 0.6683435440063477 0.7492994666099548\n",
            "600 0.6683433651924133 0.7492994666099548\n",
            "700 0.6683434247970581 0.7492995858192444\n",
            "800 0.6683413982391357 0.7492843270301819\n",
            "900 0.6683398485183716 0.749280571937561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b_u.shape)\n",
        "print(b_i.shape)\n",
        "print(b_u[users_train].shape)\n",
        "print(b_i[users_train].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voVbdR3f_bvJ",
        "outputId": "967483e2-1fdc-4924-936f-700f67149996"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([611])\n",
            "torch.Size([193610])\n",
            "torch.Size([80668])\n",
            "torch.Size([80668])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b_u[users_train])\n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mefJFnPRuE3B",
        "outputId": "38bf9717-0bc7-422a-ff30-f4170e58fa2b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.3051,  0.2166,  0.5511,  ...,  0.2166,  0.1510,  0.1029],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([2.9340, 3.5226, 3.8239,  ..., 3.4903, 3.9972, 3.8080], device='cuda:0',\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Temporal Item Bias\n",
        "전체 시간을 n_bins(=30)개의 구간(bin)으로 나누고,\n",
        "각 구간마다 item bias 생성"
      ],
      "metadata": {
        "id": "STYkewtQu86B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_users = max(users) + 1\n",
        "n_items = max(items) + 1\n",
        "\n",
        "n_bins = 30 # 몇 구간으로 나눌지\n",
        "tmin = min(times)\n",
        "trange = max(times) - tmin + 1\n",
        "\n",
        "# 전체를 n_bins로 봤을 때 t가 어느 슬롯에 있는지 나타냄.\n",
        "def timetobin(t):\n",
        "    return (t - tmin) * n_bins // trange\n",
        "\n",
        "mean = ratings_train.mean()\n",
        "b_u = torch.zeros(n_users, requires_grad=True, device=device)\n",
        "b_i = torch.zeros(n_items, requires_grad=True, device=device)\n",
        "b_it = torch.zeros(n_items, n_bins, requires_grad=True, device=device)\n",
        "\n",
        "optim = torch.optim.Adam([b_u, b_i], lr=0.1, weight_decay=0.00006)\n",
        "optim_it = torch.optim.Adam([b_it], lr=0.1, weight_decay=0.0011)\n",
        "\n",
        "criteria = torch.nn.MSELoss()\n",
        "\n",
        "for epoch in range(1000):\n",
        "    h = mean + b_u[users_train] + b_i[items_train]\n",
        "    h += b_it[items_train, timetobin(times_train)]\n",
        "    # reg = lmd * ((b_u ** 2).sum() + (b_i ** 2).sum())\n",
        "    cost = criteria(h, ratings_train)\n",
        "\n",
        "    optim.zero_grad()       # b_u, b_i의 기울기 초기화\n",
        "    optim_it.zero_grad()    # b_it의 기울기 초기화\n",
        "    cost.backward()         # 기울기 계산\n",
        "    optim.step()            # b_u, b_i 업데이트\n",
        "    optim_it.step()         # b_it 업데이트\n",
        "\n",
        "    with torch.no_grad():\n",
        "        h_train = mean + b_u[users_train] + b_i[items_train]\n",
        "        h_train += b_it[items_train, timetobin(times_train)]\n",
        "        cost_train = criteria(h_train, ratings_train)\n",
        "\n",
        "        h_test = mean + b_u[users_test] + b_i[items_test]\n",
        "        h_test += b_it[items_test, timetobin(times_test)]\n",
        "        cost_test = criteria(h_test, ratings_test)\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(epoch, cost_train.item(), cost_test.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNkkHjAwsVGw",
        "outputId": "f20e88e2-d54a-4f06-df1d-413b474435c2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.8502684235572815 0.9480273723602295\n",
            "100 0.6193946003913879 0.7452196478843689\n",
            "200 0.6194182634353638 0.7452303767204285\n",
            "300 0.6194182634353638 0.7452306151390076\n",
            "400 0.6194186806678772 0.7452344298362732\n",
            "500 0.6194183230400085 0.7452320456504822\n",
            "600 0.6194183826446533 0.7452340722084045\n",
            "700 0.6194185018539429 0.7452276945114136\n",
            "800 0.6194179058074951 0.7452341318130493\n",
            "900 0.6194093823432922 0.7452341318130493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
        "print(a)\n",
        "a[[0,1,2],[2,1,0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACzni_dFw_go",
        "outputId": "3a14054b-7f42-4053-f99b-bad5666e5f22"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 5, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_cp = 5\n",
        "user_cps = torch.zeros(n_users, n_cp)\n",
        "\n",
        "for uid in range(1, n_users):\n",
        "    times_u = times_train[users_train == uid]\n",
        "    tmin_u = min(times_u)\n",
        "    trange_u = max(times_u) - tmin_u\n",
        "    for i in range(n_cp):\n",
        "        user_cps[uid, i] = tmin_u + (i * trange_u) // (n_cp-1)\n",
        "\n",
        "user_cps = user_cps.to(device)"
      ],
      "metadata": {
        "id": "eBIN3J7BxJk3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ut_score(users, times, b_ut, gamma):\n",
        "    exps = torch.exp(-gamma * torch.abs(user_cps[users] - times.view(-1, 1)))\n",
        "    nom = (exps * b_ut[users]).sum(dim=1)\n",
        "    denom = exps.sum(dim=1)\n",
        "    return nom / denom"
      ],
      "metadata": {
        "id": "1diNAhKv0emj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n_users = max(users) + 1\n",
        "n_items = max(items) + 1\n",
        "n_bins = 30\n",
        "n_cp = 5\n",
        "tmin = min(times)\n",
        "trange = max(times) - tmin + 1\n",
        "\n",
        "def ut_score(users, times, b_ut, gamma):\n",
        "    exps = torch.exp(-gamma * torch.abs(user_cps[users] - times.view(-1, 1)))\n",
        "    nom = (exps * b_ut[users]).sum(dim=1)\n",
        "    denom = exps.sum(dim=1)\n",
        "    return nom / denom\n",
        "\n",
        "def timetobin(t):\n",
        "    return (t - tmin) * n_bins // trange\n",
        "\n",
        "mean = ratings_train.mean()\n",
        "b_u = torch.zeros(n_users, requires_grad=True, device=device)\n",
        "b_i = torch.zeros(n_items, requires_grad=True, device=device)\n",
        "b_it = torch.zeros(n_items, n_bins, requires_grad=True, device=device)\n",
        "b_ut = torch.zeros(n_users, n_cp, requires_grad=True, device=device)\n",
        "\n",
        "optim = torch.optim.Adam([b_u, b_i], lr=0.1, weight_decay=0.00006)\n",
        "optim_it = torch.optim.Adam([b_it], lr=0.1, weight_decay=0.0011)\n",
        "optim_ut = torch.optim.Adam([b_ut], lr=0.1, weight_decay=0.0)\n",
        "\n",
        "criteria = torch.nn.MSELoss()\n",
        "gamma = 9e-9\n",
        "\n",
        "for epoch in range(1000):\n",
        "    h = mean + b_u[users_train] + b_i[items_train]\n",
        "    h += b_it[items_train, timetobin(times_train)]\n",
        "    h += ut_score(users_train, times_train, b_ut, gamma)\n",
        "    # reg = lmd * ((b_u ** 2).sum() + (b_i ** 2).sum())\n",
        "    cost = criteria(h, ratings_train)\n",
        "\n",
        "    optim.zero_grad()       #b_u, b_i의 기울기 초기화\n",
        "    optim_it.zero_grad()    #b_it의 기울기 초기화\n",
        "    optim_ut.zero_grad()    #b_ut의 기울기 초기화\n",
        "    cost.backward()         #기울기 계산\n",
        "    optim.step()            # b_u, b_i 업데이트\n",
        "    optim_it.step()         # b_it 업데이트\n",
        "    optim_ut.step()         # b_ut 업데이트\n",
        "\n",
        "    with torch.no_grad():\n",
        "        h_train = mean + b_u[users_train] + b_i[items_train]\n",
        "        h_train += b_it[items_train, timetobin(times_train)]\n",
        "        h_train += ut_score(users_train, times_train, b_ut, gamma)\n",
        "        cost_train = criteria(h_train, ratings_train)\n",
        "\n",
        "        h_test = mean + b_u[users_test] + b_i[items_test]\n",
        "        h_test += b_it[items_test, timetobin(times_test)]\n",
        "        h_test += ut_score(users_test, times_test, b_ut, gamma)\n",
        "        cost_test = criteria(h_test, ratings_test)\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(epoch, cost_train.item(), cost_test.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfc3LYWl1Iq_",
        "outputId": "991bd99b-b5cb-40fd-c854-b14d1b679796"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.8148093223571777 0.9123657941818237\n",
            "100 0.6112995743751526 0.7360290288925171\n",
            "200 0.6098133325576782 0.7349340319633484\n",
            "300 0.6090230345726013 0.7344127297401428\n",
            "400 0.6085614562034607 0.7342014312744141\n",
            "500 0.6082574725151062 0.7340958714485168\n",
            "600 0.6080327033996582 0.7340258359909058\n",
            "700 0.6078512072563171 0.7339572310447693\n",
            "800 0.6076995134353638 0.7339202165603638\n",
            "900 0.6075661778450012 0.7338715195655823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UAPLSn_92kMd"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}